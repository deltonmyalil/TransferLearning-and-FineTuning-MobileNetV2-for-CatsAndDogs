{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearningOnImageNetToSOTAresultsOnCatDogClassification.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3b2DwEdqs_R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "9f35439e-47f1-437a-bb3f-0bb2c8921650"
      },
      "source": [
        "# Dependency installs\n",
        "!pip install tensorflow --upgrade &> /dev/null\n",
        "!pip install tqdm &> /dev/null\n",
        "# DataSet download\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O ./cats_and_dogs_filtered.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-24 12:47:05--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 66.102.1.128, 2a00:1450:400c:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|66.102.1.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘./cats_and_dogs_filtered.zip’\n",
            "\n",
            "\r          ./cats_an   0%[                    ]       0  --.-KB/s               \r         ./cats_and   6%[>                   ]   4.01M  14.0MB/s               \r        ./cats_and_  48%[========>           ]  32.01M  59.0MB/s               \r./cats_and_dogs_fil 100%[===================>]  65.43M  97.4MB/s    in 0.7s    \n",
            "\n",
            "2020-02-24 12:47:06 (97.4 MB/s) - ‘./cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNfHG6sBxiEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as pltprint(\"Fine Tuning achieved a performance difference of {} percent from the transfer learning model\".format(validation_accuracy_fine_tuned-validation_accuracy))\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm_notebook\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from contextlib import redirect_stdout # To save model.summary() to file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pATPrIAfQ8MW",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLJmh43GzoCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unpacking the dataset\n",
        "dataset_path = \"./cats_and_dogs_filtered.zip\"\n",
        "zip_object = zipfile.ZipFile(dataset_path, mode='r')\n",
        "zip_object.extractall(\"./\")\n",
        "zip_object.close()\n",
        "\n",
        "# Setting the dataset paths\n",
        "dataset_path_new = \"./cats_and_dogs_filtered/\"\n",
        "train_dir = os.path.join(dataset_path_new, \"train\")\n",
        "validation_dir = os.path.join(dataset_path_new, \"validation\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMoooBnw8GM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper function to save the model.summary() to filename.txt\n",
        "def save_model_summary_to_file(filename, model):\n",
        "    with open(filename, 'w') as f:\n",
        "        with redirect_stdout(f):\n",
        "            model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_2XriBt0jOJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "2a8125e9-48f4-401e-d30f-46f9cf264e9d"
      },
      "source": [
        "# Image shape set to constant for further use\n",
        "IMG_SHAPE = (128, 128, 3)\n",
        "\n",
        "# Loading a pretrained model\n",
        "# Using the MobileNetV2\n",
        "# MobileNetV2 is trained on the imagenet dataset.\n",
        "# include_top is set to false as we need to use our custom dataset instead of \n",
        "#   feeding in imagenet data/dimensions\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, \n",
        "                                               include_top=False, \n",
        "                                               weights=\"imagenet\")\n",
        "\n",
        "# base_model.summary() # Saving to file instead\n",
        "save_model_summary_to_file('BaseModel_MobileNetV2.txt', base_model)\n",
        "\n",
        "# Freezing the base model\n",
        "base_model.trainable = False"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
            "9412608/9406464 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvqtbeYA99_N",
        "colab_type": "text"
      },
      "source": [
        "## Defining a custom head for the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq0K2MbQ6Lkj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "115066d5-f50d-4378-9dea-ebddc2e46b6b"
      },
      "source": [
        "base_model.output # shape = (batch, height, width, channels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'out_relu/Identity:0' shape=(None, 4, 4, 1280) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7PuhqLN-IGK",
        "colab_type": "text"
      },
      "source": [
        "4x4x1280 is not suited for the output layer of the custom head. Either just outright flatten it (still too many parameters). The other option is to use Pooling - GlobalAveragePooling. Global pooling takes the pooling from the whole input instead of processing parts of it at a time with a sliding stride window. It reduces the input size significantly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2PYdIvu-oyv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "de9bf2d0-1f16-458d-99cf-ec18aedb2387"
      },
      "source": [
        "# Layer that pools across all the filters. Just pass base model's o/p to it.\n",
        "# Note the new sweet way of giving the input to one layer as (another_layer.output)\n",
        "# I never knew that\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "global_average_layer # shape = (batch, channels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'global_average_pooling2d/Identity:0' shape=(None, 1280) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45GdBS2SBibe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making the prediction layer\n",
        "prediction_layer = tf.keras.layers.Dense(units=1, activation='sigmoid')(global_average_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhxpX8M3CQF0",
        "colab_type": "text"
      },
      "source": [
        "## Defining our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDSi8H_ICSPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine the base model with our model by passing in inputs and outputs\n",
        "model = tf.keras.models.Model(inputs=base_model.input,\n",
        "                              outputs=prediction_layer)\n",
        "\n",
        "# Saving the summary to file\n",
        "save_model_summary_to_file('combinedModel.txt', model=model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-JV0clGDaL-",
        "colab_type": "text"
      },
      "source": [
        "## Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBua-iksDcd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizer: RMSP: proven to be the best opt for MobileNetv2\n",
        "#               smaller learning rate since we are using a pretrained network\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZaR9qj8I4LN",
        "colab_type": "text"
      },
      "source": [
        "## Creating Data Generators for Preprocessing\n",
        "\n",
        "MobileNetV2 Only supports certain input sizes\n",
        "\n",
        "(96,96), (128,128), (160,160), (192,192), (224,224)\n",
        "\n",
        "So, we need to resize\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "will do the necessary preprocessing steps\n",
        "\n",
        "\n",
        "General practice is to create two generators - one for training and one for testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPJ--40kJpDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize\n",
        "data_gen_train = ImageDataGenerator(rescale=1/255.)\n",
        "data_gen_validation = ImageDataGenerator(rescale=1/255.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e1eYeXgM8-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "71e84603-11e3-424b-ee4b-1733a56b7fa3"
      },
      "source": [
        "# Specify where to find the dataset\n",
        "# Takes the path to a  directory and generates batches of augmented data\n",
        "train_generator = data_gen_train.flow_from_directory(directory=train_dir,\n",
        "                                                     target_size=(128,128),\n",
        "                                                     class_mode='binary',\n",
        "                                                     batch_size=128)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkIMxT_uNkqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "969419f3-8b5e-456a-aff7-1bbc1ff37c54"
      },
      "source": [
        "validation_generator = data_gen_validation.flow_from_directory(directory=validation_dir,\n",
        "                                                               target_size=(128,128),\n",
        "                                                               class_mode='binary',\n",
        "                                                               batch_size=128)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyBPXtXlOI-v",
        "colab_type": "text"
      },
      "source": [
        "## Training the Transfer Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rJud3liOMN5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "outputId": "53b62e71-eeff-448b-d277-5905f66bab35"
      },
      "source": [
        "# Instead of the usual model.train, use model.fit_generator()\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_generator)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 16 steps, validate for 8 steps\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 9s 557ms/step - loss: 0.4534 - accuracy: 0.7945 - val_loss: 0.3588 - val_accuracy: 0.8700\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 9s 566ms/step - loss: 0.4261 - accuracy: 0.8125 - val_loss: 0.3340 - val_accuracy: 0.8770\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 9s 578ms/step - loss: 0.4020 - accuracy: 0.8290 - val_loss: 0.3145 - val_accuracy: 0.8820\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 9s 564ms/step - loss: 0.3806 - accuracy: 0.8480 - val_loss: 0.2977 - val_accuracy: 0.8870\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 9s 561ms/step - loss: 0.3611 - accuracy: 0.8610 - val_loss: 0.2852 - val_accuracy: 0.8890\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 9s 548ms/step - loss: 0.3441 - accuracy: 0.8650 - val_loss: 0.2691 - val_accuracy: 0.9010\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 9s 545ms/step - loss: 0.3290 - accuracy: 0.8770 - val_loss: 0.2594 - val_accuracy: 0.9020\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 9s 548ms/step - loss: 0.3153 - accuracy: 0.8825 - val_loss: 0.2484 - val_accuracy: 0.9080\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 9s 550ms/step - loss: 0.3027 - accuracy: 0.8915 - val_loss: 0.2416 - val_accuracy: 0.9050\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 9s 564ms/step - loss: 0.2914 - accuracy: 0.8950 - val_loss: 0.2354 - val_accuracy: 0.9110\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe6ef2e10b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Rog9Z2xQV_1",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating the Transfer Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYoPf6W0QY4U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "b84129fc-e733-42cb-a945-b2967996c4b4"
      },
      "source": [
        "validation_loss, validation_accuracy = model.evaluate_generator(generator=validation_generator)\n",
        "print(\"Transfer Learning Accuracy is \", validation_accuracy)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-17-43bbaaed147b>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.evaluate, which supports generators.\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Transfer Learning Accuracy is  0.911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpVY6D4VRChQ",
        "colab_type": "text"
      },
      "source": [
        "# Fine Tuning the Model Further"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iGIGK71RGDv",
        "colab_type": "text"
      },
      "source": [
        "Fine tune only the top(output-ish) few layers to adapt to the custom domain: Because the lower(input-ish) layers will probably extract features like line edges, color differences etc which are common across all animals and the upper(output-ish) layers will extract the more specific features like eyes, nose, ears etc which are specidic to cats and dogs. To adapt to a domain, it is important to make the model adapt to these specific cases of dog ears and cat ears which are found near the output as opposed to something which is generic for both dogs and cats line edges and color gradients found near the inputs.\n",
        "\n",
        "In short, fine tune the outputtish layers. One common approach is to only fine tune the output dense and softmax layers to convert the 10 animals dataset to cats and dogs.\n",
        "\n",
        "Fine tune only after transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqHzjVmrRUV1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "169a93c2-a057-4be1-ed5c-2e3cc9b5e031"
      },
      "source": [
        "print(\"Total number of layers in the model is \", len(base_model.layers))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of layers in the model is  155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5-Qf6nKXmNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unfreeze some of the top(output-ish) layers of the base model\n",
        "# For this, first unfreeze the whole model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Let's fine tune after the 100th layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Now freeze all layers near the input till 100\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Now out of the 150 layers, the the last(output-ish) 55 layers can be fine tuned"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi8-njrGY0xg",
        "colab_type": "text"
      },
      "source": [
        "## Compile the Fine Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrblCeBMegMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW_83sVtfK9P",
        "colab_type": "text"
      },
      "source": [
        "## Training(Fine Tuning) the Fine Tuning Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo0xypmufWEn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "07741b4a-2553-4da2-8594-cceaa956b541"
      },
      "source": [
        "model.fit_generator(generator=train_generator, \n",
        "                    epochs=5, \n",
        "                    validation_data=validation_generator)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 16 steps, validate for 8 steps\n",
            "Epoch 1/5\n",
            "16/16 [==============================] - 15s 949ms/step - loss: 0.1466 - accuracy: 0.9470 - val_loss: 0.0843 - val_accuracy: 0.9660\n",
            "Epoch 2/5\n",
            "16/16 [==============================] - 9s 577ms/step - loss: 0.0147 - accuracy: 0.9995 - val_loss: 0.0836 - val_accuracy: 0.9710\n",
            "Epoch 3/5\n",
            "16/16 [==============================] - 9s 574ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9690\n",
            "Epoch 4/5\n",
            "16/16 [==============================] - 9s 570ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9670\n",
            "Epoch 5/5\n",
            "16/16 [==============================] - 9s 572ms/step - loss: 8.4406e-04 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe6f22c6b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYccPhDHgOjv",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating the Fine Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JBBc2oAgRmV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "fba08e5e-3d06-47fa-9f1d-aec6b5316017"
      },
      "source": [
        "validation_loss_fine_tuned, validation_accuracy_fine_tuned = model.evaluate_generator(\n",
        "    generator=validation_generator\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGwC2xUugtIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "04383ad2-039e-4feb-c2a2-c213aa1fea19"
      },
      "source": [
        "print(\"Validation accuracy after fine tuning is \", validation_accuracy_fine_tuned)\n",
        "\n",
        "print(\"Model improved\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy after fine tuning is  0.966\n",
            "Model improved\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}